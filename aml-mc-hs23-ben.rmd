---
title: "aml-mc-hs23-ben"
author: "Si Ben Tran"
date: "31.12.2023"
subtitle: Product Affinity Modelling
---

# Aufgaben
Aufgabe: Entwickle und evaluiere Affinitätsmodelle für Kreditkarten auf 
Basis von transaktionellen Kundeninformationen mittels binärer 
Klassifikation in Hinsicht auf personalisierte Werbekampagnen.

# Inhalt
• Aufbereitung eines Modellierungsdatensatz,  
• Modellentwicklung und systematischer Performance-Vergleich,  
• Vergleich der Haupteinflussfaktoren und Top-N Listen der Modelle,  
• Modell-Selektion und systematische Hyperparameter-Optimierung,  
• Modellvereinfachung und -beschreibung für Non-Data Scientist.  

# Libraries Laden
```{r echo=FALSE}
library(tidyverse)
library(tidymodels)
library(DataExplorer)
library(lubridate)
library(eeptools)
library(zoo)
```


# 1. Daten
Laden, transformieren und überprüfen der Datenqualität mittels 
explorativer Datenanalyse; entfernen von Junior-Kreditkarten Kunden.

## 1.1 Laden
Insgesamt werden 8 verschiedene csv Files zur Verfuegung gestellt.
Die Beschreibungen der Daten sind hier zu finden: https://sorry.vse.cz/~berka/challenge/PAST/index.html

```{r read dataframe}
# alle file namen
file_names <- c(
  "account.csv", "card.csv", "client.csv", "disp.csv",
  "district.csv", "loan.csv", "order.csv", "trans.csv"
)

# leere liste fuer dataframes
data_frames <- list()

# For loop durch file_name
for (file_name in file_names) {
  # path definieren
  file_path <- file.path("xselling_banking_data", file_name)

  # daten einlesen und in liste speichern
  data_frames[[file_name]] <- read.csv(file_path, header = TRUE, sep = ";")
}

# dataframes zuweisen
account <- data_frames[["account.csv"]]
card <- data_frames[["card.csv"]]
client <- data_frames[["client.csv"]]
disp <- data_frames[["disp.csv"]]
district <- data_frames[["district.csv"]]
loan <- data_frames[["loan.csv"]]
order <- data_frames[["order.csv"]]
trans <- data_frames[["trans.csv"]]
```


## 1.2 transformieren
### 1.2.1 account
Die Tabelle account besitzt 4 Spalten, die account_id selbst, district_id welches auf die tabelle district verweist. 
Frequency welches die Haeufigkeit der Austellung von Kontoauszuegen definiert sowie ein datum. 

Die Werte von frequency und datum muessen umgeaendert werden, weiter aendern wir ebenfalls den spaltenname von frequency zu issuance_statement_frequency.
```{r wrangle account}
# Frequency
account <- account %>%
  mutate(frequency = case_when(
    frequency == "POPLATEK MESICNE" ~ "MONTHLY ISSUANCE",
    frequency == "POPLATEK TYDNE" ~ "WEEKLY ISSUANCE",
    frequency == "POPLATEK PO OBRATU" ~ " ISSUANCE AFTER TRANSACTION",
    TRUE ~ frequency # Keep other values unchanged
  )) %>%
  rename(issuance_statement_frequency = frequency)

# Datum
account$date <- ymd(account$date)

# Zuweisen zur df liste
data_frames[["account.csv"]] <- account

account %>% sample_n(size = 5)
```

### 1.2.2 card
Die Tabelle card beinhaltet die card_id, dis_id (verweist auf disp df) 
type der Karte und issued. 
Bei card aendern wir das Format in YYMMDD um und ignorierien die Zeit. 
(Auch gemaess der Dokumentation, ist keine Zeit vorgesehen.)
```{r wrangle card}
# Datum formatieren
card$issued <- as_date(ymd_hms(card$issued))

# Zuweisen zur df Liste
data_frames[["card.csv"]] <- card

# Df ausgeben
card %>% sample_n(size = 5)
```

### 1.2.3 client
client Tabelle hat client_id, birht_number mit einem speziellen Format, YYMMDD
fuer Maenner und YYMM + 50 DD fuer Frauen. Also sprich, wurden bei Frauen der Geburtsmonat um 50 addiert. Weiter gibt es noch die district_id, welches auf die district Tabelle verweist. 
```{r wrangle client}
# Funktion zur Geschlechterbestimmung
get_gender <- function(birth_number) {
  year <- as.integer(substr(birth_number, 1, 2))
  month <- as.integer(substr(birth_number, 3, 4))
  day <- as.integer(substr(birth_number, 5, 6))

  # Bei Frauen wird der Geburtsmonat um 50 addiert
  if (month > 12) {
    gender <- "female"
  } else {
    gender <- "male"
  }

  return(gender)
}

# Geschlecht bestimmen und als neue Spalte hinzufügen
client$gender <- sapply(client$birth_number, get_gender)


# filter nach Frauen, erstelle jahr (19XX), Monat - 50 und Tag Spalte sowie Geburtstag.
client_female <- client %>%
  filter(gender == "female") %>%
  mutate(birth_number,
    year =
      as.integer(paste("19", as.character(substr(birth_number, 1, 2)), sep = "")),
    month =
      as.integer(substr(birth_number, 3, 4)) - 50,
    day =
      as.integer(substr(birth_number, 5, 6)),
    birth_day =
      make_date(year, month, day)
  ) %>%
  select(client_id, year, month, day, birth_number = birth_day, district_id, gender)

# Analog fuer Maenner
client_male <- client %>%
  filter(gender == "male") %>%
  mutate(birth_number,
    year =
      as.integer(paste("19", as.character(substr(birth_number, 1, 2)), sep = "")),
    month =
      as.integer(substr(birth_number, 3, 4)),
    day =
      as.integer(substr(birth_number, 5, 6)),
    birth_day =
      make_date(year, month, day)
  ) %>%
  select(client_id, year, month, day, birth_number = birth_day, district_id, gender)

# Anzahl Zeilen ueberpruefen, ob diese mit dem Ursprungs DataFrame uebereinstimmen.
if (nrow(rbind(client_female, client_male)) == nrow(client)) {
  client <- rbind(client_female, client_male)
}

# Berechnung des Alters auf basisjahr 31.12.1999
client$age <- age_calc(dob = client$birth_number, enddate = as.Date("1999-12-31"), units = "years", precise = FALSE)

# zuweisen zur df liste
data_frames[["client.csv"]] <- client

# ausgeben
client %>% sample_n(size = 5)
```

### 1.2.4 disp
disp hat disp_id, client_id, welches auf client dataframe verweist und account_id, welches auf account Tabelle verweist sowie den typ, wobei nur OWNER einen Dauerauftrag erstellen koennen und Kredite aufnehmen koennen.
```{r wrangle disp}
disp %>% sample_n(size = 5)
```

### 1.2.5 district
district hat nummerierte Spalten von A1 - A16. Dabei sind die Kurzel jeweils auf der Website aufgelistet fuer was diese stehen. Wir bennen die Spalten um, damit wir eine Ahnung haben, mit was wir arbeiten sollten. 

A1  district_id/district code	
A2	district name	
A3	region	
A4	no. of inhabitants	
A5	no. of municipalities with inhabitants < 499	
A6	no. of municipalities with inhabitants 500-1999	
A7	no. of municipalities with inhabitants 2000-9999	
A8	no. of municipalities with inhabitants >10000	
A9	no. of cities	
A10	ratio of urban inhabitants	
A11	average salary	
A12	unemploymant rate '95	
A13	unemploymant rate '96	
A14	no. of enterpreneurs per 1000 inhabitants	
A15	no. of commited crimes '95	
A16	no. of commited crimes '96

```{r wrangle district}
district <- district %>% select(
  district_id = A1, district_name = A2,
  region = A3, num_of_habitat = A4,
  num_of_small_town = A5, num_of_medium_town = A6,
  num_of_big_town = A7, num_of_bigger_town = A8,
  num_of_city = A9, ratio_of_urban = A10,
  average_salary = A11, unemploy_rate95 = A12,
  unemploy_rate96 = A13, n_of_enterpren_per1000_inhabit = A14,
  no_of_crimes95 = A15, no_of_crimes96 = A16
)

# zuweisen zur df liste
data_frames[["district.csv"]] <- district

district %>% sample_n(size = 5)
```

### 1.2.6 loan
Loan hat loan_id, account_id (verweis auf account Tabelle), date in YYMMDD Format, amount, duration, payments, status.
Aendern werden wir payments zu monthly_payments und die Werte von
status. 
'A' stands for contract finished, no problems, => contract finished
'B' stands for contract finished, loan not payed, => finished contract, loan not payed
'C' stands for running contract, OK so far, => running contract
'D' stands for running contract, client in debt => client in debt

Weiter checken wir, ob ein Account mehrere Loans haben kann, Gruppieren nach account und zaehlen die Anzahl Zeilen. Diese Fuegen wir dann spaeter zu unserem Loan DataFrame hinzu als weiteres Feature. 

```{r wrangle loan}
loan$date <- ymd(loan$date)

loan <- loan %>%
  mutate(status = case_when(
    status == "A" ~ "contract finished",
    status == "B" ~ "finished contract, loan not paid",
    status == "C" ~ "running contract",
    status == "D" ~ "client in debt",
  ))

num_of_loan_df <- loan %>%
  group_by(account_id) %>%
  summarize(num_of_loan = n()) %>%
  arrange(desc(num_of_loan))

num_of_loan_df

loan <- inner_join(
  x = loan,
  y = num_of_loan_df,
  by = "account_id"
)


# Zuweisen zur df liste
data_frames[["loan.csv"]] <- loan

loan %>% sample_n(size = 5)
```

### 1.2.7 order
die order Tabelle besteht aus order_id, account_id, bank_to (einzigartige Komibination aus 2 Buchstaben), account_to (zu welchem Account), amount, k_symbol (klassifizierung der Zahlung)
k_symbol wird auf englisch uebersetzt

Da es accounts gibt die keine Orders haben, versuchen wir den Order Datensatz zu erweitern, indem wir von account, account_id einen left join machen. Somit erhalten wir alle account auch diejenigen die keine order besitzen. Diese haben NA Werte, welche wir dann mit 0 beim Amount und "UNKOWN" bei k_symbol ersetzen.

Ein account kann mehrere Orders haben, um spaeter einfacher joinen zu koenen versuchen wir durch aggregieren nach account_id die Summe, Mittelwert, Median Ausgaben zu erhalten. Bei den Kategorischen Spalte k_symbol versuchen wir diese One-Hot zu encoden. 
```{r wrangle order}
order <- order %>%
  mutate(k_symbol = case_when(
    k_symbol == "POJISTNE" ~ "INSURRANCE PAYMENT",
    k_symbol == "SIPO" ~ "HOUSHOLD",
    k_symbol == "UVER" ~ "LOAN PAYMENT"
  ))

order$k_symbol[is.na(order$k_symbol)] <- "UNKOWN"


# create a dataframe that contains all account_id from account
account_id_df <- account %>%
  select(account_id)

# make a left join with order, every account that doesnt have an order will have NA values
order <- left_join(
  x = account_id_df,
  y = order,
  by = "account_id"
) %>% # create a column has_order if the row is complete
  mutate(has_order = !rowSums(is.na(.))) # if k_symbol NA then replace with "UNKOWN"

order$k_symbol[is.na(order$k_symbol)] <- "UNKOWN"

order$amount[is.na(order$amount)] <- 0

# Aggregating amount
aggregated_amount <- order %>%
  group_by(account_id) %>%
  summarise(
    sum_amount = sum(amount, na.rm = TRUE),
    mean_amount = mean(amount, na.rm = TRUE),
    median_amount = median(amount, na.rm = TRUE),
    min_amount = min(amount, na.rm = TRUE),
    max_amount = max(amount, na.rm = TRUE),
    num_of_orders = sum(amount != 0) # Count non-zero orders
  )


# create a column has_order if the sum_amount is 0 == False
aggregated_amount$has_order <- aggregated_amount$sum_amount != 0

aggregated_amount

# Creating dummies
dummies_k_symbol <- order %>%
  select(account_id, k_symbol) %>%
  pivot_wider(
    names_from = k_symbol,
    values_from = k_symbol,
    values_fill = 0,
    values_fn = length
  )

dummies_k_symbol

# Merging dataframes
order <- left_join(aggregated_amount, dummies_k_symbol, by = "account_id")

# zuweisen zur df liste
data_frames[["order.csv"]] <- order

order %>% sample_n(size = 5)
```


### 1.2.8 trans
Die trans Tabelle hat trans_id, account_id, date, type, operation, amount und banalce, k_symbol (analog zu order) bank und account


type, operation und k_symbol Werte werden auf Englisch uebersetzt
```{r wrangle trans}
trans <- trans %>%
  mutate(
    date = ymd(date),
    type = case_when(
      type == "PRIJEM" ~ "CREDIT",
      type == "VYDAJ" ~ "WITHDRAWAL"
    ),
    operation = case_when(
      operation == "VYBER KARTOU" ~ "CREDIT CARD WITHDRAWAL",
      operation == "VKLAD" ~ "CREDIT IN CASH",
      operation == "PREVOD Z UCTU" ~ "COLLECTION FROM ANOTHER BANK",
      operation == "VYBER" ~ "WITHDRAWAL IN CASH",
      operation == "PREVOD NA UCET" ~ "REMITTANCE TO ANOTHER BANK"
    ),
    k_symbol = case_when(
      k_symbol == "POJISTNE" ~ "INSURRANCE PAYMENT",
      k_symbol == "SLUZBY" ~ "STATEMENT PAYMENT",
      k_symbol == "UROK" ~ "INTEREST CREDITED",
      k_symbol == "SANKC. UROK" ~ "INTERES IF NEGATIVE BALANCE",
      k_symbol == "SIPO" ~ "HOUSHOLD",
      k_symbol == "DUCHOD" ~ "OLD-AGE PENSION",
      k_symbol == "UVER" ~ "LOAN PAYMENT",
    )
  )

# Zuweisen zur df liste
data_frames[["trans.csv"]] <- trans

trans %>% sample_n(size = 5)
```

## 1.3 Datenqualität mittels eda

### 1.3.1 Fehlende Werte
Wir erkennen, dass die Transaktions Daten in der Tabelle order und trans fehlende Werte aufweisen. 

```{r fehlende Werte}
# check for missing values in each dataframe
for (i in 1:length(data_frames)) {
  df_name <- names(data_frames)[i] # Get the dataframe name
  cat("Missing values in", df_name, ":\n")
  print(sum(is.na(data_frames[[i]])))
}
```

### 1.3.1 District - Fehlende Werte

Bei genauer Betrachtung des Dataframes "district" ist aufgefallen, dass bei dessen Einlesen die Spalten "unemploy_rate95" und "no_of_crime95" als Zeichenketten (Character) eingelesen wurden. Bei beiden Spalten wurde der ein "?" verwendet statt NA. 
Hier in diesem Code Abschnitt imputieren den fehlenden Wert mit dem Mittelwert der jeweiligen Spalte.

```{r wramgle missing values, warning=FALSE}
# Datentyp convertieren
district$unemploy_rate95 <- as.numeric(district$unemploy_rate95)
district$no_of_crimes95 <- as.numeric(district$no_of_crimes95)

# fehlende Werte plotten
plot_missing(district)

# Imputation mittels mean
district$unemploy_rate95[is.na(district$unemploy_rate95)] <- median(district$unemploy_rate95, na.rm = TRUE)

district$no_of_crimes95[is.na(district$no_of_crimes95)] <- median(district$no_of_crimes95, na.rm = TRUE)

# fehlende Werte nach imputation plotten
plot_missing(district)
```


### 1.3.2 Data Explorer

Wir nutzen Data Explorer für eine erste Grobe Übersicht zu unseren Daten zu erhalten. 

```{r perform eda with DataExplorer}
# Function to perform EDA on a dataframe
perform_eda <- function(df, df_name) {
  # Create a data exploration report for the dataframe
  title <- paste("Exploratory Data Analysis for", df_name)
  create_report(df, report_title = title)

  # You can add more EDA steps here, such as additional plots and analysis
}

# Specify your directory path
path <- "eda-dataexplorer-reports"

# Check if directory exists
if (dir.exists(path)) {
  # List all files in directory
  list_of_files <- list.files(path)

  # Check if directory is empty
  if (length(list_of_files) == 0) {
    # Iterate through the list of dataframes and perform EDA on each
    for (i in 1:length(data_frames)) {
      df_name <- names(data_frames)[i] # Get the dataframe name
      perform_eda(data_frames[[i]], df_name)
    }
  } else {
    cat("Directory is not empty. Not running the EDA code.")
  }
} else {
  cat("Specified path does not exist. Please check the path and try again.")
}
```

Mittels der Funktion perform_eda() generiert für jedes Dataframe eine Explorative Datenanalyse in html Format. Diese sind unter dem Verzeichnis: eda-dataexplorer-reports zu finden. 
Wir betrachten nun alle Dateframes vom Dataexplorer und halten unsere Kentnisse in diesem Abschnitt fest. 

account: 
Account besitzt keine fehlende Werte. Weiter fällt stark auf, dass bei issuance_statement_frequency der meiste vorkommende Wert MONTHLY ISSUANCE ist. 

card:
card besitzt keine fehlende Werte. Beim Barplot vom Typ sehen wir, dass classic die am häufigsten vertretene Klasse ist. Gefolgt wird diese von Junior und auf dem dritten Platz, mit am wenigsten vorkommenden sind gold.

client:
client weist keine fehlende Werte im Datensatz auf. Die Altersverteilung ist leicht linksschief. Wir erkennen im korrelationsplot, dass Jahr und Alter korrelieren, was jedoch nicht verwunderlich ist.

disp:
disp weist keine fehlende Werte im Datensatz auf. Die am meisten vorkommende Variable von type ist OWNER. DISPONENT kommt 1/4 mal weniger vor als OWNER.

district:
district weist ebenfalls keine fehlende Werte auf. average_salary ist rechtsschief verteilt. 

loan:

order:

trans:

## 1.4 Junioren entfernen

### 1.4.1 entfernen von Junior Kreditkarten Kunden
```{r remove junior card}
# checken, welche Variabeln vorhanden sind.
print(paste("Kartentypen:", unique(card$type)))

# !junior dataframe
card_clean <- subset(card, type != "junior")

# junior dataframe
card_junior <- subset(card, type == "junior")

# Berechne Differenz von rows zwischen card_junior und card
print(paste("Anzahl entfernte junior Karten:", nrow(card_junior)))

# entfernen von allen disp_id in disp Dataframe, die in card_junior vorkommen.  (1:1)
disp_clean <- subset(disp, !(disp_id %in% unique(card_junior$disp_id)))
print(paste("Anzahl entfernte disp_id, die von card_junior kommen:", nrow(disp) - nrow(disp_clean)))
```

### 1.4.2 entfernen von junge Kunden

Wir untersuchen die Junioren genauer indem wir eine Visualisierung erstellen, indem wir die Altersverteilungen der Kunden sehen aufgrund dessen, welche Karten sie besitzen. 
Dazu muessen wir schon einige Tabellen miteinander joinen um dies tun zu koennen. 
Weiter haben wir eine Statistische Auswertung des Alters gemacht, indem wir nach card.type gruppieren und das jeweilige Alter aggregieren. Es stellt sich heraus, das die aelteste Person 25 Jahre Alt ist und eine junior Karte bestizt. Da wir in unserem Modell nicht die Junioren ansprechen wollen, entfernen wir zusaetzlich noch alle Kunden die juenger als 26 sind. Relevant bleiben uns somit nur die accounts_id die ueber 25 Jahre alt sind. 

```{r}
# inner join by client_id
client_disp <- inner_join(
  x = client,
  y = disp,
  by = "client_id",
  suffix = c(".client", ".disp")
) %>%
  select(
    client_id,
    district_id,
    disp_id,
    account_id,
    everything()
  ) %>%
  rename(
    "year.client" = "year",
    "month.client" = "month",
    "day.client" = "day",
    "birht_number.client" = "birth_number",
    "gender.client" = "gender",
    "age.client" = "age",
    "type.disp" = "type"
  )

# left join
client_disp_card <- left_join(
  x = client_disp,
  y = card,
  by = "disp_id",
  suffix = c("", ".card")
) %>%
  mutate(has_card = !rowSums(is.na(.))) %>%
  select(-c(disp_id, card_id)) %>%
  rename(
    "type.card" = "type",
    "issued.card" = "issued",
    "has_card.card" = "has_card"
  )

client_disp_card

# create age distribution and color them with type.card
ggplot(client_disp_card, aes(
  x = age.client,
  color = type.card
)) +
  geom_histogram(
    alpha = 0.5,
    fill = "white"
  ) +
  labs(title = "Verteilung von Alter unterteilt nach Kartentyp", x = "Alter", y = "Anzahl") +
  facet_wrap(~type.card)

# get statistical information grouped by type.card for age
client_disp_card %>%
  group_by(type.card) %>%
  summarize(
    mean_age = mean(age.client),
    median_age = median(age.client),
    min_age = min(age.client),
    max_age = max(age.client),
    quantile_75 = quantile(age.client, 0.75)
  )

# create boxplot for age distribution, for each card.type
ggplot(client_disp_card, aes(
  x = type.card,
  y = age.client,
  color = type.card
)) +
  geom_boxplot() +
  labs(title = "Verteilung von Alter unterteilt nach Kartentyp", x = "Kartentyp", y = "Alter")

# remove all junior in type.card but keep NA
client_disp_card_rm_junior <- client_disp_card %>%
  filter(type.card != "junior" | is.na(type.card))

# get all account_ids that are older than 25 years old
client_ids_older_than_25 <- client_disp_card_rm_junior %>%
  filter(age.client > 25) %>%
  select(client_id)

client_ids_older_than_25
```



# 2. Kombinieren 
Kombinieren der Informationen zu Kunden und Bankdienstleistungen.

Durch unsere Skizze die unter als "skizze-tabelle-joinen" abgelegt wurde, wissen wir nun wie die Tabellen miteinander verknuepft sind und konnen so einen Datensatz von Kunden und einen Datensatz von Bankdienstleistungen erstellen.  

## 2.1 client - disp

Wir innen joinen client und disp mit client_id, renamen die Spaltenamen und fügen jeweils ein suffix hinzu, um später noch eine Übersicht zu haben, von welcher Tabelle die Spalte entspringt. Beim inner joinen verlieren wir keine Kunden. Nach dem Joinen wissen wir von jedem Kunden, was für eine Art type der Kunde ist. OWNER oder DISPONENT.  

```{r cmobine client-disp}
# client und disp weisen eine 1:1 relation auf client_id auf.
print(paste("Anzahl Zeilen client_ids_older_than_25 df:", nrow(client_ids_older_than_25)))
print(paste("Anzahl Zeilen disp df:", nrow(disp)))

# Inner join client with client_ids_older_than_25 to remove junior and clients age <= 25
client <- inner_join(
  x = client,
  y = client_ids_older_than_25,
  by = "client_id"
)

# inner join by client_id
client_disp <- inner_join(
  x = client,
  y = disp,
  by = "client_id",
  suffix = c(".client", ".disp")
) %>%
  select(
    client_id,
    district_id,
    disp_id,
    account_id,
    everything()
  ) %>%
  rename(
    "year.client" = "year",
    "month.client" = "month",
    "day.client" = "day",
    "birht_number.client" = "birth_number",
    "gender.client" = "gender",
    "age.client" = "age",
    "type.disp" = "type"
  )

print(paste("Anzahl Zeilen client_disp df:", nrow(client_disp)))
client_disp
```

### 2.1.1 gender vs. type
Die meisten unserer Kunden sind vom typ her OWNER. Das Geschlecht ob man OWNER oder DISPONENT ist sehen bei beiden Verteilungen ähnlich gleich aus. 

```{r eda}
ggplot(client_disp, aes(
  x = age.client,
  color = gender.client
)) +
  geom_histogram(
    alpha = 0.2,
    fill = "white",
    position = "dodge"
  ) +
  labs(
    title = "Verteilung von Alter unterteilt nach Geschlecht und Typ",
    x = "Alter",
    y = "Anzahl"
  ) +
  facet_grid(gender.client ~ type.disp)
```

## 2.2 +card

Wir joinen client_disp mit card über disp_id. Nicht jeder Kunde besitzt eine Karte, somit ist ein left join auf client_disp unsere Wahl, um keine Kunden zu verlieren. Weiter wurde eine weitere spalte erstellt, die uns markiert, ob der Kunde eine Karte besitzt oder nicht. Dies könnte später noch relevant werden bei der Evaluierung unsere Modelle.
```{r +card}
# Weiter joinen wir client_disp und card mit disp_id. Auch hier besteht eine 1:1 Beziehung.

# Wir erkennen jedoch, dass es clienten gibt, die keine Karte besitzen. aus diesem Grund

print(paste("Anzahl Zeilen card df:", nrow(card_clean)))

# left join
client_disp_card <- left_join(
  x = client_disp,
  y = card_clean,
  by = "disp_id",
  suffix = c("", ".card")
) %>%
  mutate(has_card = !rowSums(is.na(.))) %>%
  select(-c(client_id, disp_id, card_id)) %>%
  rename(
    "type.card" = "type",
    "issued.card" = "issued",
    "has_card.card" = "has_card"
  )

print(paste("Anzahl Zeilen client_disp_card df:", nrow(client_disp_card)))
client_disp_card
```
### 2.2.1 type vs. has_card
Aus der Visualisierung erkennen wir, dass keine Disponenten existieren die eine Karte besitzen. Aus diesem Grund filtern wir unseren Datensatz nur nach Owner, da wir diesen Personen eine Karte anbieten, bzw Karten wie classic oder gold besitzen bzw. verkaufen koennten. 

```{r eda}
ggplot(client_disp_card, aes(
  x = age.client,
  color = has_card.card
)) +
  geom_histogram(
    alpha = 0.5,
    fill = "white"
  ) +
  labs(title = "Verteilung von Alter unterteilt nach Kartentyp und Art", x = "Alter", y = "Anzahl") +
  facet_grid(type.card ~ type.disp)
```

### 2.2.2 groupby account_id
Kann ein Kunde Disponent und OWNER gleichzeitig sein?

Ja es gibt Account die mehrere Zeilen beinhalten. 
```{r eda}
# groupby account and count number of rows
client_disp_card %>%
  group_by(account_id) %>%
  summarize(num_of_rows = n()) %>%
  arrange(desc(num_of_rows))
```

## 2.3 Filter nach OWNER

Durch das Filtern verlieren wir 869 Kunden. Es bleiben von den 5369 Kunden nun noch 4500. 
```{r filter for owner}
# Filtern nach type.disp == "OWNER"
print(paste("Anzahl entfernte Zeilen von client_disp_card df:", nrow(client_disp_card) - nrow(client_disp_card %>% filter(type.disp == "OWNER"))))

client_disp_card <- client_disp_card %>% filter(type.disp == "OWNER")
client_disp_card
```

### 2.3.1 groupby account_id

Das das Filtern stellen wir nun fest, dass jeder Kunde nur ein Account bei der Bank besitzt. Diese koennen wir nun nutzen, um mit dem DataFrame account zu joinen. 
```{r eda}
# groupby account and count number of rows
client_disp_card %>%
  group_by(account_id) %>%
  summarize(num_of_rows = n()) %>%
  arrange(desc(num_of_rows))
```


## 2.4 + account
Durch die Erkentnisse von 2.3.1 koennen wir nun einen Inner Join durchfuehren von unserem vorhanden dataframe client-disp-card mit account Tabelle. 
Die Anzahl der Kunden bleibt somit gleich auf 4500. 
```{r +account}
# Ein Account kann mehrere disponenten haben.

print(paste("Anzahl Zeilen account df:", nrow(account)))
print(paste("Anzahl Zeilen client_disp_card:", nrow(client_disp_card)))


client_disp_card_account <- inner_join(
  x = account,
  y = client_disp_card,
  by = "account_id"
) %>%
  rename(
    "district_id.account" = "district_id.x",
    "district_id.client" = "district_id.y",
    "issuance_statement_frequency.account" = "issuance_statement_frequency",
    "account_creation_date.account" = "date"
  )


print(paste("Anzahl Zeilen client_disp_card_account df:", nrow(client_disp_card_account)))
client_disp_card_account
```

## 2.5 loan - account

Wir betrachten hier nun account und loan getrennt von unserem gejointen Dataframe. Erst in einem zweiten Schritt joinen wir beide Dataframes dann miteinander. Da ein Account ein Kredit haben kann oder nicht, fuehren wir einen left_join auf account ueber account_id.

```{r loan-account}
# Ein account kann ein Kredit haben oder auch nicht.
account_loan <- left_join(
  x = account,
  y = loan,
  by = "account_id"
) %>%
  mutate(has_loan.loan = !rowSums(is.na(.))) %>%
  rename(
    "date.loan" = "date.y",
    "amount.loan" = "amount",
    "duration.loan" = "duration",
    "payments.loan" = "payments",
    "status.loan" = "status",
    "num_of_loan.loan" = "num_of_loan"
  ) %>%
  select(-c(loan_id, district_id, issuance_statement_frequency, date.x))

account_loan
```

### 2.5.1 NA Werte
Durch das Joinen haben wir viele Spalten erhalten die NA Werte aufweisen. Bzw. nur die Spalten die von Loan kommen. Diese werden durch 0 oder no_loan ersetzt, da diese Accounts keinen Kredit besitzen. Beim Datum belassen wir die NA Werte

```{r reaplce NA values}
# reaplce NA values with 0 or no_loan
account_loan <- account_loan %>%
  mutate(
    amount.loan = ifelse(is.na(amount.loan), 0, amount.loan),
    duration.loan = ifelse(is.na(duration.loan), 0, duration.loan),
    payments.loan = ifelse(is.na(payments.loan), 0, payments.loan),
    status.loan = ifelse(is.na(status.loan), "no_loan", status.loan),
    num_of_loan.loan = ifelse(is.na(num_of_loan.loan), 0, num_of_loan.loan)
  )
```


### 2.5.2 amount vs. payments

Wir betrachten hier nun account und loan getrennt von unserem gejointen Dataframe. Erst in einem zweiten Schritt joinen account_loan und client_disp_card_account mit der Spalte account_id zusammen und fuehren eine kurze explorative Datenanalyse durch. 

Interessant zu sehen ist, dass die meisten Kredite schon abbezahlt wurden die eine Dauer von 12 Monaten aufweisen. 

Viele Account haben keinen Kredit aufgenommen.

```{r eda, warning=FALSE}
# Kredithoehe vs. Payments mit dauer und status
sample_n(account_loan, size = 1000) %>%
  ggplot(aes(
    x = amount.loan,
    y = payments.loan,
    shape = as.factor(duration.loan),
    color = status.loan
  )) +
  geom_point(alpha = 1) +
  labs(
    title = "Zahlung vs. Menge Kredit, unterteilt nach Dauer und",
    x = "Kreditmenge",
    y = "Zahlung"
  )

# Anzahl Kredite unterteilt nach Status
account_loan %>%
  ggplot(aes(
    x = has_loan.loan,
    fill = status.loan
  )) +
  geom_bar(position = "stack") +
  labs(
    title = "Stacked Barplot",
    x = "Kredit",
    y = "Anzahl"
  )
```


## 2.6 + account_loan

Wir joinen nun beide groesseren Dataframes ueber account_id. Beide Dataframes weisen 4500 Zeilen, somit haben wir nach dem joinen immer noch 4500 Kunden, welche 22 Features aufweisen. 
```{r +amount_loan}
# account_loan mit client_disp_card_district_account joinen
client_disp_card_account_loan <- inner_join(
  x = account_loan,
  y = client_disp_card_account,
  by = "account_id"
)

print(paste("Anzahl Zeilen client_disp_card_account df:", nrow(client_disp_card_account_loan)))
client_disp_card_account_loan
```



### 2.6.1 loan vs. card?
Was uns nun intressiert ist der Zusammenhang zwischen eine Karte zu besitzen und einen Kredit aufzuweisen. 

Es gibt Kunden die eine Karte haen und einen Kredit, analog gibt es auch Kunden die keine Karte haben, aber einen Kredit oder nicht. Somit behalten wir in unserem Datensatz die Kundschaft bei.

```{r eda}
client_disp_card_account_loan %>%
  ggplot(aes(
    x = has_loan.loan,
    fill = has_card.card
  )) +
  geom_bar(position = "dodge") +
  labs(
    title = "Barplot",
    x = "Kredit vorhanden?",
    y = "Anzahl"
  ) +
  facet_grid(type.card ~ issuance_statement_frequency.account)
```

### 2.6.2 Anzahl Kunden?
Wir überprüfen unser DataFrame ob eine Zeile einen Kunden entspricht indem wir nach account_id gruppieren und die Rows zaehlen.

In unserem DataFrame ist jede Zeile ein Kunde. Somit konnte jedem Kunden ein Bank Account zugewiesen werden. 
```{r eda}
# groupby account and count number of rows
client_disp_card_account_loan %>%
  group_by(account_id) %>%
  summarize(num_of_rows = n()) %>%
  arrange(desc(num_of_rows))
```

## 2.7 +order

Durch den Inner join mit order haben wir weiterhin die gleiche Anzahl Kunden.


```{r +order}
# inner join by account_id client_disp_card_district_account_loan und order

print(paste("Anzahl Zeilen client_disp_card_account_loan_order df:", nrow(client_disp_card_account_loan)))
print(paste("Anzahl Zeilen order :", nrow(order)))


client_disp_card_account_loan_order <- inner_join(
  x = client_disp_card_account_loan,
  y = order,
  by = "account_id"
) %>%
  rename(
    "sum_amount.order" = "sum_amount",
    "mean_amount.order" = "mean_amount",
    "median_amount.order" = "median_amount",
    "min_amount.order" = "min_amount",
    "max_amount.order" = "max_amount",
    "num_of_orders.order" = "num_of_orders",
    "num_insurrance_payment.order" = "INSURRANCE PAYMENT",
    "num_household.order" = "HOUSHOLD",
    "num_loan_payment.order" = "LOAN PAYMENT",
    "num_unkown.order" = "UNKOWN",
    "has_order.order" = "has_order"
  ) %>%
  arrange(account_id)

print(paste("Anzahl entfernte Zeilen von client_disp_card_account_loan df:", nrow(client_disp_card_account_loan) - nrow(client_disp_card_account_loan_order)))

client_disp_card_account_loan_order
```

## 2.8 +district
Wir erweitern unseren Datensatz mit dem district. Wichtig dabei zu beachten ist, dass wir jeweils einen district fuer die Filiale der Bank haben und einen district fuer den Kunden. In unserem Fall joinen wir unser Dataframe mit dem des Kunden, da uns dieser mehr interessiert, ob geographische Einfluesse den Kauf eines Bank Produktes.

```{r +district}
print(paste("Anzahl Zeilen district df:", nrow(district)))
print(paste("Anzahl Zeilen client_disp_card_account_loan_order:", nrow(client_disp_card_account_loan_order)))

client_disp_card_account_loan_order_district <- left_join(client_disp_card_account_loan_order %>% rename("district_id" = "district_id.client"),
  district,
  by = "district_id"
) %>%
  rename(
    "district_name.district" = "district_name",
    "region.district" = "region",
    "num_of_habitat.district" = "num_of_habitat",
    "num_of_medium_town.district" = "num_of_medium_town",
    "num_of_small_town.district" = "num_of_small_town",
    "num_of_big_town.district" = "num_of_big_town",
    "num_of_bigger_town.district" = "num_of_bigger_town",
    "num_of_city.district" = "num_of_city",
    "ratio_of_urban.district" = "ratio_of_urban",
    "average_salary.district" = "average_salary",
    "unemploy_rate95.district" = "unemploy_rate95",
    "unemploy_rate96.district" = "unemploy_rate96",
    "n_of_enterpren_per1000_inhabit.district" = "n_of_enterpren_per1000_inhabit",
    "no_of_crimes95.district" = "no_of_crimes95",
    "no_of_crimes96.district" = "no_of_crimes96"
  ) %>%
  select(-c(district_id))

print(paste("Anzahl Zeilen client_disp_card_account_loan_order_district df:", nrow(client_disp_card_account_loan_order_district)))

data <- client_disp_card_account_loan_order_district

data
```

## 2.9 Data
```{r}
data
```


## 2.10 trans
Ein Account kann mehrere Transaktionen gemacht haben. 
- droppen von unnoetigen Transaktion spalten
- Aggregation fuer Numerische (Mean, Median etc...)
- Aggregation mir Rolling Window von balance und
- OneHotEncoding fuer Kategorische

```{r +trans?}
trans <- trans %>%
  select(-c(trans_id, account)) %>%
  arrange(account_id)
trans
```

# 3. Identifizierung
Identifizieren bestehender Kreditkartenkäufer inkl. Bestimmung des Kaufdatums und Rollup-Fensters, definiert durch 1 Monat Lag und 12 Monate History vor Kreditkartenkauf.

## 3.1 Identifizierung bestehender Kreditkartenkaeufer und Kaufdatum

selektieren vom grossen dataframe has_card nach True und selektieren account_id und issued.card

```{r}
# create a dataframe where has_card.card == TRUE
account_ids_has_card <- data %>%
  filter(has_card.card == TRUE) %>%
  select(account_id, issued.card)

account_ids_has_card
```

## 3.2 Rollup-Fenster von Käufer

Das Rollup Fenster definieren wir indem wir vom Kaufdatum 13 Monate subtrahieren (12 Monate History + 1 Monat Lag). Vor dem Kauf einer Kreditkarte kann es gut sein, dass der Kunde sich 1 Monat schon davor entschieden hat eine Karte zu beantragen und diese noch von der Bank verarbeitet werden muss. Aus diesem Grund filtern wir die Transaktionellen Daten zwischen den Bereich start_date (kaufdatum.datum - 13 Monate) und start_lag_date (kaufdatum.card - 1 Monat). Somit erhalten wir unsere Transkationsdaten fuer Kunden die eine Karte haben im gegebenen Zeitfenster.


```{r}
# vom Kaufdatum -13 Monate von Kunden die eine Karte besitzen
account_ids_has_card <- account_ids_has_card %>%
  mutate(
    start_date = issued.card %m-% months(13),
    start_lag_date = issued.card %m-% months(1)
  )

account_ids_has_card

# get from transaction all accounts that got a card and filter also by its range
buyers <- inner_join(
  x = account_ids_has_card,
  y = trans,
  by = "account_id"
) %>%
  filter(date >= start_date & date <= start_lag_date) %>%
  select(-c(start_date, start_lag_date))

# extract year and month
buyers$year_month <- format(as.Date(buyers$date), "%Y-%m")

buyers

# reorder col
buyers <- buyers %>%
  select(account_id, issued.card, date, year_month, type:bank)

# check transaction within range
buyers
```

## 3.3 Roll-up Fenster Pivotieren
Ein Kunde der eine Karte hat, kann schon mehrere Transaktionen in einem Monat haben. Damit wir diese spaeter mit den non-buyers vergleichen koennen, extrahieren wir das Jahr und den Monat, gruppieren und pivotieren das Dataframe. So erhaltlen wir auf einer Zeile einen Kunden und deren zugehorigen Jahr-Monat als Spalte. Die Werte werden bewusst auf 1 oder 0 gesetzt, wobei 1 dafuer steht, dass eine Transaktion gemacht wurde in diesem Jahr-Monat und 0 fuer keine. 

```{r}
# select from buyers only account_id and year_month, group by and count number of rows, if there is a transaction in this year-month set value to 1 else 0
buyers_pivot <- buyers %>%
  select(account_id, year_month) %>%
  group_by(account_id, year_month) %>%
  summarize(count = n(), .groups = "drop") %>%
  mutate(value = 1) %>%
  pivot_wider(
    id_cols = account_id,
    names_from = year_month,
    values_from = value,
    values_fill = 0
  ) %>%
  select(account_id, sort(buyers$year_month))


buyers_pivot

# calculate the rowsum of each row and add them as a new column, sort ascending
buyers_pivot %>%
  mutate(rowsum = rowSums(across(-account_id))) %>%
  arrange(rowsum)

# ueberlegung, ob kauefer die ein weniger als 12 rowsums haben gedroppt werden. (ca. 150 Kauefer)
```

## 3.4 Roll-up visualization
Wir schreiben eine Funktion die uns erlaubt nach beliebige accounts zu filtern die eine Karte besitzen und in unserem Roll-up Fenster sind. Anschliessend fuehren wir eine Visualisierung von balance durch und zeichnen noch zusaetzlich ein rollingwindow von 30 Tagen ein. Wichtig dabei zu beachten ist, dass das lag-Monat nicht mit visualisiert wird! Diese Visualisierung erlaubt es uns, Kunden mit dem Produkt einer Karte besser zu verstehen. 

```{r}
visualize_account_balance <- function(transactions,
                                      accounts_to_filter,
                                      window_size = 30,
                                      show_df = FALSE) {
  # Filter transactions by account
  filtered_transactions <- transactions %>%
    filter(account_id %in% accounts_to_filter)

  # Check if filtered data frame is empty
  if (nrow(filtered_transactions) == 0) {
    warning("The provided account_id(s) do not appear in the transactions dataset.")
    return(NULL)
  }

  # Calculate rolling mean
  trans_with_rolling_mean <- filtered_transactions %>%
    arrange(account_id, date) %>%
    group_by(account_id) %>%
    mutate(rolling_mean = rollmean(balance, k = window_size, fill = NA, align = "center"))

  if (show_df) {
    print(trans_with_rolling_mean)
  }

  # visualisere balanace and rolling mean
  plot <- ggplot(trans_with_rolling_mean, aes(x = date)) +
    geom_line(aes(
      y = balance,
      color = as.factor(account_id)
    )) +
    geom_line(
      aes(
        y = rolling_mean,
        color = as.factor(account_id)
      ),
      linetype = "solid"
    ) +
    geom_vline(
      xintercept = as.numeric(unique(filtered_transactions$kaufdatum.card)),
      linetype = "dotdash", color = "black",
    ) +
    labs(
      title = paste(window_size, "-Day Rolling Mean Over Time"),
      x = "Date",
      y = "Balance",
      color = "Account ID"
    )

  return(plot)
}

visualize_account_balance(buyers,
  accounts_to_filter = c(7, 14),
  window_size = 30,
  show_df = TRUE
)
```


## 3.4 EDA von Karten Kaeufer

Wir schauen uns an, was ueberhaupt ein Kartenkaeufer ausmacht und explorieren den komibinerten Datensatz
```{r fig.width=10, fig.height=10}
# loan?
# create a barplot and count has_loan
data %>%
  ggplot(aes(
    x = has_loan.loan,
    fill = has_card.card
  )) +
  geom_bar(position = "dodge") +
  labs(
    title = "Barplot von Kredit",
    x = "Kredit vorhanden?",
    y = "Anzahl"
  )

# issuance_statement_frequency.account?
# create a barplot and count issuance_statement_frequency.account
data %>%
  ggplot(aes(
    y = issuance_statement_frequency.account,
    fill = has_card.card
  )) +
  geom_bar(position = "dodge") +
  labs(
    title = "Barplot von issuance_statement_frequency.account",
    y = "issuance_statement_frequency.account",
    x = "Anzahl"
  )

# age distribution
data %>%
  ggplot(aes(
    x = age.client,
    fill = has_card.card
  )) +
  geom_histogram(bins = 35) +
  labs(
    title = "Histogramm von Alter",
    x = "Alter",
    y = "Anzahl"
  )

# has order?
data %>%
  ggplot(aes(
    x = has_order.order,
    fill = has_order.order
  )) +
  geom_bar(position = "dodge") +
  labs(
    title = "Barplot von Dauerauftrag",
    x = "Dauerauftrag vorhanden?",
    y = "Anzahl"
  )

# gender.client?
# create barplot for gender
data %>%
  ggplot(aes(
    x = gender.client,
    fill = has_card.card
  )) +
  geom_bar(position = "dodge") +
  labs(
    title = "Barplot nach Geschlecht",
    x = "Geschlecht",
    y = "Anzahl"
  )

# district_name.district?
data %>%
  ggplot(aes(
    y = district_name.district,
    fill = has_card.card
  )) +
  geom_bar(position = "dodge") +
  labs(
    title = "Barplot nach Distrikt",
    x = "Anzahl",
    y = "Distrikt"
  )



# region.district?
data %>%
  ggplot(aes(
    y = region.district,
    fill = has_card.card
  )) +
  geom_bar(position = "dodge") +
  labs(
    title = "Barplot nach Region",
    x = "Anzahl",
    y = "Region"
  )
```


## 3.5 Testing

Wir versuchen aus den Transaktionsdaten von den buyer die Attribute in einem geeignetem Format zu kriegen. Dabei unterscheiden wir die Kategorische und Numerische Spalten. Grundsaetzlich gruppieren wir nach account_id und year_month und zaehlen bei den kategorischen variabeln wie oft diese variable vorkommt. Bei den numerischen Werten berechnen wir Attribute wie Summe, Mittelwert, Median etc.... anschliessend joinen wir alles zu einem Dataframe und pivotieren diese. Beim pivotieren erhalten wir zu viele Spalten (mehr als 1000). (Behalten den Code, vlt brauchen wir den spaeter)
```{r}
# Extracting year and month from the date column
buyers$year_month <- format(as.Date(buyers$date), "%Y-%m")

buyers

# Handling categorical datatypes in transaction

trans_type <- buyers %>%
  group_by(account_id, year_month, type) %>%
  summarise(count_type = n()) %>%
  pivot_wider(names_from = type, values_from = count_type, values_fill = list(count_type = 0)) %>%
  rename(
    "n_credit.trans.type" = "CREDIT",
    "n_withdrawl.trans.type" = "WITHDRAWAL",
    "n_NA.trans.type" = "NA"
  )

trans_type

trans_operation <- buyers %>%
  group_by(account_id, year_month, operation) %>%
  summarise(count_operation = n()) %>%
  pivot_wider(names_from = operation, values_from = count_operation, values_fill = list(count_operation = 0)) %>%
  rename(
    "n_withdrawal_in_cash.trans.operation" = "WITHDRAWAL IN CASH",
    "n_NA.trans.operation" = "NA",
    "n_credit_in_cash.trans.operation" = "CREDIT IN CASH",
    "n_remittance_to_anoth_bank.trans.operation" = "REMITTANCE TO ANOTHER BANK",
    "n_collec_from_anoth_bank" = "COLLECTION FROM ANOTHER BANK"
  )

trans_operation

trans_k_symbol <- buyers %>%
  group_by(account_id, year_month, k_symbol) %>%
  summarise(count_type = n()) %>%
  pivot_wider(names_from = k_symbol, values_from = count_type, values_fill = list(count_type = 0)) %>%
  rename(
    "n_interest_credited.trans.ksymbol" = "INTEREST CREDITED",
    "n_statement_payment.trans.ksymbol" = "STATEMENT PAYMENT",
    "n_NA.trans.ksymbol" = "NA",
    "n_houshold.trans.ksymbol" = "HOUSHOLD",
    "n_insurrance_pay.trans.ksymbol" = "INSURRANCE PAYMENT",
    "n_loan_pay.trans.ksymbol" = "LOAN PAYMENT",
    "n_old_age_pension.trans.ksymbol" = "OLD-AGE PENSION",
    "n_interes_if_neg_balance.trans.ksymbol" = "INTERES IF NEGATIVE BALANCE",
  )

trans_k_symbol

# handling numerical values
trans_amount_balance <- buyers %>%
  group_by(account_id, year_month) %>%
  summarise(
    sum_amount.trans = sum(amount, na.rm = TRUE),
    mean_amount.trans = mean(amount, na.rm = TRUE),
    median_amount.trans = median(amount, na.rm = TRUE),
    min_amount.trans = min(amount, na.rm = TRUE),
    max_amount.trans = max(amount, na.rm = TRUE),
    sum_balance.trans = sum(balance, na.rm = TRUE),
    mean_balance.trans = mean(balance, na.rm = TRUE),
    median_balance.trans = median(balance, na.rm = TRUE),
    min_balance.trans = min(balance, na.rm = TRUE),
    max_balance.trans = max(balance, na.rm = TRUE),
    num_of_trans.trans = n(),
  )

trans_amount_balance

# Join everthing together into one big dataframe
trans_aggregated <- inner_join(trans_type, trans_operation, by = c("account_id", "year_month")) %>%
  inner_join(trans_k_symbol, by = c("account_id", "year_month")) %>%
  inner_join(trans_amount_balance, by = c("account_id", "year_month"))

trans_aggregated <-
  trans_aggregated

trans_aggregated_wider <- trans_aggregated %>%
  pivot_wider(
    names_from = year_month,
    values_from = -c(account_id, year_month)
  )

trans_aggregated_wider
```

# 4. Nicht-Käufer
Bestimmen der Nicht-Käufer zum Vergleich (inkl. Rollup-Fenster).

## 4.1 Bestimmung von Nicht-Käufer

Wir haben 3094 potenzielle Kunden denen wir eine Karte anbieten könnten.

(Kontaktstunde vom 24.10.2023)
Weiter schauen wir uns an, wann der account erstellt wurde und berechnen 12 Monate in die "zukunft", damit wir Neukunden nicht als potenzielle Kunden betrachten, da deren Verhalten am Anfang ein anderer ist, als bei einem langjaehrigen Kunden. 
```{r}
# create a dataframe where has_card.card == FALSE
account_ids_no_cards <- data %>%
  filter(has_card.card == FALSE) %>%
  select(account_id, account_creation_date.account)

account_ids_no_cards
```

## 4.2 Fiktives issued für Nicht-Käufer definieren

Erste Idee:
Idee: Wir haben einen pool von non_buyers_data und einen pool von buyers_data, welche ein issued.card Datum haben. 
Nun wollen wir für einen non-buyer einen möglichst ähnlichen buyer finden und nehmen dann diesen issue.card Datum und fügen diese dann dem non-buyer hinzu. 
Dabei soll berücksichtigt werden, dass: 
- Zeitspanne (issued.date - 13 Monate -> Transkationen bei non-buyers vorhanden?
- Alter ? 
- Geschlecht ? 
- Region ? 
- has_loan ?
- has_order ?
- issuance_statement_frequency.account)

wie? 
Iteriere durch non-buyers account, filtere ob bsp. Geschlecht gleich ist, Region gleich ist, has_loan gleich ist, has_order oder issuance_statement. Es bleiben nur noch die buyers übrig die diesen krieterien entsprechen mit dem non-buyer. Anschliessend vergleiche, ob der non-buyer und buyer mindestens 12 Monate überlappngen aufweist, falls ja, berechne nun das Alter, und das Alter mit der tiefsten Differenz, von dem buyer nimm das issued.card Datum und füge das dem account_ids_no_cards zur entsprechenden non-buyer id hinzu. 

Feedback von Dani (Kontaktstunde 24.10.2023):
Idee nicht gut, da wir dann das Modell die Möglichkeit vorweg schon weg nehmen aufgrund von den Attributen zu lernen.  

Neue idee: 
Von Buyers Transaktionsdataframe in dem Rollup Fenster erstellen. (issued.card - 13 Monate bis start_lag_date)
buyers Transaktionsdataframe, vom Datum -> Jahr und Monat extrahiere und dann pivotiere. 
Anschliessend mit 1 oder 0 auffuellen. (Siehe 3.3)

Analog mache ich das gleiche fuer non buyers, filtere aber jedoch nicht das Fenster. 
Anschliessend picke ich random einen buyer aus und nehme den grössten jaccard wert mit non buyer in bezug auf die transkationsdaten jahr monat. Falls ein Non-Buyer mehrere aehnliche Buyers zugewiesen werden kann, so wird random ein Buyer gepickt und deren issued.date dem Non-Buyer uebertragen.

```{r}
# get transaktion dataframe from non-buyers
non_buyers <- inner_join(
  x = account_ids_no_cards,
  y = trans,
  by = "account_id"
)

# extract month
non_buyers$year_month <- format(as.Date(non_buyers$date), "%Y-%m")

non_buyers
```

### 4.2.1 Fenster von Nicht Kauefer bearbeiten

(Kontaktstunde vom 24.10.2023)
Wir filtern die Transaktionsdaten, damit wir die Transkationsdaten von Neukunden (Kunden die im ersten Jahr bei der Bank sind), nicht haben. 

```{r}
# create a column where you add one year to creation date
non_buyers <- non_buyers %>%
  mutate(
    end_date = account_creation_date.account %m+% months(12),
  )

# Exclude date range between account_creation_date.account and end_date from non_buyers
non_buyers <- non_buyers %>%
  filter(date < account_creation_date.account | date > end_date)

# reorder dataframe non_buyers
non_buyers <- non_buyers %>%
  select(account_id, date, year_month, type:bank)

non_buyers
```

### 4.2.2 Non-buyer pivotieren
Wir pivotieren die non-buyers, analog wie bei den buyers. Jede Spalte repraesntiert das Jahr und den Monat, die Werte 1 oder 0 sagen aus, ob eine Transaktion durchgefuehrt wurde oder nicht. Da wir beim pivotieren nicht die gleiche Anzahl an spalten erhalten, wurde noch von den Transaktions Dataset das minimale und maximale Datum herausgefiltert und eine Liste gebastelt mit einem Abstand von jeweils einen Monat. Anschliessend ueberpruefen wir, ob das Jahr-Monat vorkam, falls nicht wird eine Spalte erstellt und diese mit 0 aufgefuellt. wir sortieren beide Dataframes und erhalten somit die gleiche Anzahl spalten fuer die buyers (im Roll-up Fenster) und non-buyers. 

```{r}
# pivot non-buyers
non_buyers_pivot <- non_buyers %>%
  select(account_id, year_month) %>%
  group_by(account_id, year_month) %>%
  summarize(count = n(), .groups = "drop") %>%
  mutate(value = 1) %>%
  pivot_wider(
    id_cols = account_id,
    names_from = year_month,
    values_from = value,
    values_fill = 0
  ) %>%
  select(account_id, sort(non_buyers$year_month))

# extract from trans date the min and max date but just year-month
min_date <- min(format(as.Date(trans$date), "%Y-%m"))
max_date <- max(format(as.Date(trans$date), "%Y-%m"))

# append "-01" to min_date and max_date
min_date <- paste(min_date, "-01", sep = "")
max_date <- paste(max_date, "-01", sep = "")

# create an array between min_date and max_date 1 months apart
date_range <- seq.Date(from = as.Date(min_date), to = as.Date(max_date), by = "month")

year_month_range <- format(date_range, "%Y-%m")

# if there is a column that does not exist in non_buyers_pivot and buyer but in year_month_range, add it and set value to 0
for (col in year_month_range) {
  if (!(col %in% colnames(non_buyers_pivot))) {
    non_buyers_pivot[[col]] <- 0
  }
}

# same for buyers_pivot
for (col in year_month_range) {
  if (!(col %in% colnames(buyers_pivot))) {
    buyers_pivot[[col]] <- 0
  }
}

# sort both dataframe by year_month range
non_buyers_pivot <- non_buyers_pivot %>%
  select(account_id, sort(year_month_range))

buyers_pivot <- buyers_pivot %>%
  select(account_id, sort(year_month_range))

buyers_pivot
non_buyers_pivot
```


## 4.3 Bestimmung von fiktives issued_date
Mit den beiden Dataframes aus 4.2.2 koennen wir nun den Jaccard-index berechnen. Sprich die groesste Zeitfensterueberlappungen von Roll-up Fenster Buyer und non-buyers. Da es sein kann, dass mehrere ueberlappungen von non-buyers und buyers gleich sind, picken wir random ein issued date in diesem fall vom buyer aus und fuegen dem den non-buyer hinzu. 

```{r}
# WICHTIG: Sortieren nach account_id aufsteigend!

# sort all dataframes by account_id ascending with a function
sort_by_account_id <- function(df) {
  df <- df %>%
    arrange(account_id)
}

# apply function to all 4 dataframes in this codeblock
non_buyers_pivot <- sort_by_account_id(non_buyers_pivot)
buyers_pivot <- sort_by_account_id(buyers_pivot)
account_ids_has_card <- sort_by_account_id(account_ids_has_card)
account_ids_no_cards <- sort_by_account_id(account_ids_no_cards)

account_ids_has_card
account_ids_no_cards
buyers_pivot
non_buyers_pivot
```

### 4.3.1 Umwandeln in Matrizen
Wir wandeln die buyers_pivot un non_buyers_pivot in matrizen um, und droppen dabei account_id, da diese bei der Berechnung von Jaccard nicht dabei sein sollte. Aus diesem Grund war das sortieren vorhin sehr wichtig, damit spaeter eine Zuweisung wieder auf deren Indexe gemacht werden kann. 
```{r}
# drop in buyers_pivot and non_buyers_pivot
buyers_pivot_matrix <- buyers_pivot %>%
  select(-c(account_id)) %>%
  as.matrix()

buyers_pivot_matrix

# select one row from buyers_pivot_matrix
# buyers_pivot_matrix[1, 1:ncol(buyers_pivot_matrix)]


non_buyers_pivot_matrix <- non_buyers_pivot %>%
  select(-c(account_id)) %>%
  as.matrix()

non_buyers_pivot_matrix
```

### 4.3.2 Jaccard Index Testing
Hier testen wir den Jaccard Index und schreiben eine Funktion dafuer.
```{r}
# Define two binary matrices
matrix1 <- matrix(c(
  1, 0, 0, 1,
  0, 1, 1, 0,
  1, 1, 0, 1
), nrow = 3, byrow = TRUE)

matrix2 <- matrix(c(
  0, 1, 0, 1,
  1, 0, 1, 0,
  1, 1, 1, 0
), nrow = 3, byrow = TRUE)

# Define function to calculate Jaccard Index for two rows
jaccard_index <- function(row1, row2) {
  intersection <- sum(row1 * row2)
  union <- sum(row1 + row2 > 0)
  return(intersection / union)
}

# Calculate row-wise Jaccard Index for each combination of rows
nrows1 <- nrow(matrix1)
nrows2 <- nrow(matrix2)
jaccard_matrix <- matrix(0, nrow = nrows1, ncol = nrows2)
for (i in 1:nrows1) {
  for (j in 1:nrows2) {
    jaccard_matrix[i, j] <- jaccard_index(matrix1[i, ], matrix2[j, ])
  }
}

# Print the result
print(jaccard_matrix)
```

### 4.3.3 Anwendung Jaccard index
Wir wenden die Funktion an unserem echten Datensatz und erhalten eine 691x3086 Jaccard Matrix. 691 Zeilen von den buyers und 3086 von den Non Buyers. 
```{r}
# Calculate row-wise Jaccard index for each combination of rows with buyers_pivot_matrix and non_buyers_pivot_matrix
nrows1 <- nrow(buyers_pivot_matrix)
nrows2 <- nrow(non_buyers_pivot_matrix)
jaccard_matrix <- matrix(0, nrow = nrows1, ncol = nrows2)
for (i in 1:nrows1) {
  for (j in 1:nrows2) {
    jaccard_matrix[i, j] <- jaccard_index(buyers_pivot_matrix[i, ], non_buyers_pivot_matrix[j, ])
  }
}

# print nrow and ncol of jaccard_matrix
print(nrow(jaccard_matrix))
print(ncol(jaccard_matrix))
```

### 4.3.4 Indexe
Da wir 3086 Spalten haben, muessten wir diese nun in Spalten betrachten, um den hoechsten Jaccard Wert und der zugehoerigen Index aus der Zeile herauszufinden. Wir koennen somit fuer jeden non-buyer den hochsten Wert und dem entsprechenden buyer herausholen, indem wir den index der zeile nehmen und diesen den issued.date nachschauen und dies dann im index von der Spalte im non-buyer account hinzufuegen.
```{r}
# for each column, get the highstes value and its corresponding row index and column index in a dataframe.
jaccard_df <- data.frame()
for (i in 1:ncol(jaccard_matrix)) {
  col_values <- jaccard_matrix[, i]
  # höchster Spaltenwert
  max_value <- max(col_values)
  # alle row indexe
  max_indices <- which(col_values == max_value)
  # eines davon auswaehlen random
  selected_index <- sample(max_indices, 1)

  # hinzufuegen zum dataframe
  jaccard_df <- rbind(jaccard_df, data.frame(
    row_index = selected_index,
    col_index = i,
    jaccard_value = max_value
  ))
}

# rename row_index to buyers_card_index and col_index to non_buyers_card index
jaccard_df <- jaccard_df %>%
  rename(
    buyers_card_index = row_index,
    non_buyers_card_index = col_index
  )

jaccard_df

# Create row index in account_ids_has_card and account_ids_no_cards
account_ids_has_card <- account_ids_has_card %>%
  mutate(
    row_index = row_number()
  ) %>% select(buyers_card_index = row_index, account_id:start_lag_date)

account_ids_has_card

account_ids_no_cards <- account_ids_no_cards %>%
  mutate(
    row_index = row_number()
  ) %>% select(non_buyers_card_index = row_index, account_id:account_creation_date.account)

account_ids_no_cards
```

### 4.3.5 Fiktives Issued Date
Hier fuegen wir das fiktive issued date zu unserem account_ids_no_cards dataframe hinzu indem wir auf deren indexe zugreifen.
```{r}
# inner join jaccard_df with account_ids_no_cards by non_buyers_card_index
non_buyer_with_buyers_card_index <- inner_join(
  x = account_ids_no_cards,
  y = jaccard_df,
  by = "non_buyers_card_index"
) %>% select(-c(non_buyers_card_index, account_creation_date.account)) %>% 
  rename("non_buyer_account_id" = "account_id")

non_buyer_with_buyers_card_index

# left join account_ids_no_cards with account_ids_has_card by buyers_card_index
non_buyers_fictive_date <- left_join(
  x = non_buyer_with_buyers_card_index,
  y = account_ids_has_card,
  by = "buyers_card_index"
) %>% select(-c(start_date, start_lag_date, buyers_card_index)) %>% rename(
  "buyer_account_id" = "account_id",
  "fictive_issued.card" = "issued.card"
) %>% select(non_buyer_account_id, fictive_issued.card, jaccard_value, buyer_account_id)

non_buyers_fictive_date %>% arrange(desc(jaccard_value))

non_buyers_fictive_date %>% arrange(non_buyer_account_id)

```


## 4.4 Vergleich 
Visualisierungstest von non_buyer_account_id = 91 und buyer_account_id 3725, mittels Funktion aus 3.4

Die Funnktion visualisiert, dass die Ueberlappung von non-buyer und buyer funktioniert hat und der Code von 4.3 funktioniert! 
```{r}
visualize_account_balance(trans,
  accounts_to_filter = c(91, 3725),
  window_size = 30,
  show_df = FALSE
)

visualize_account_balance(trans,
  accounts_to_filter = c(1390, 2409),
  window_size = 30,
  show_df = FALSE
)
```

## 4.5 Rollup-Fenster Vergleich
Wir selektieren von den Non-Buyers die account_id und das fiktive Datum, erstellen die Roll-up Fenster analog zu den Buyer und filtern die trans Dataset in den entsprechenden Roll-up Fenster und vergleichen diese dann mit der visualisierungs Funktion fuer die gleichen Accounts wie bei 4.3.4

```{r}
# als Vergleich account_ids_has_card
account_ids_has_card <- account_ids_has_card %>% select(account_id:start_lag_date
)
account_ids_has_card

# Create analoges Dataframe
account_ids_without_card <- non_buyers_fictive_date %>% select(account_id = non_buyer_account_id, fictive_issued.card) %>% mutate(
  start_date = fictive_issued.card %m-% months(13),
  start_lag_date = fictive_issued.card %m-% months(1))


account_ids_without_card

non_buyers <- inner_join(
  x = account_ids_without_card,
  y = trans,
  by = "account_id"
) %>% filter(
  date >= start_date & date <= start_lag_date) %>% 
  select(-c(start_date, start_lag_date)) %>% 
  mutate(year_month = format(as.Date(date), "%Y-%m")) %>% select(account_id, issued.card = fictive_issued.card, date, year_month, type:bank)


# print transaction table from buyers and non-buyers
buyers
non_buyers

# create transaction_roll_up window for buyers and non-buyers by concat buyers and non_buyers dataframe
trans_within_range <- rbind(buyers, non_buyers)
trans_within_range

visualize_account_balance(trans_within_range,
  accounts_to_filter = c(91, 3725),
  window_size = 30,
  show_df = FALSE
)

visualize_account_balance(trans_within_range,
  accounts_to_filter = c(1390, 2409),
  window_size = 30,
  show_df = FALSE
)

```

# 5 Recap
Da wir bis zu diesem Schritt vieles gemacht haben, gibt es hier ein kurzes Re-Cap, um die Übersicht wieder zu gewinnen, falls man diese bis dahin verloren hat. 

In den Abschnitten 1 bis und mit 1.2.8 haben wir die Daten eingelesen und versucht einen Zusammenhang der Tabellen zu verstehen, gegebenenfalls auch Data Wrangling betrieben. 

Im Abschnitt 1.3 - 1.3.2 wurden gegebenenfalls die Na Werte imputiert und eine Explorative Datenanalyse durchgeführt.

Im Abschnitt 1.4 haben wir Junioren Karten entfernt und auch eine Altersgrenze definiert, in denen sich darüber unsere Potenzielle Kunden befinden.

Im Abschnitt 2 bis und mit 2.9 haben wir die Tabellen miteinenader verknüpft und ein grosses Dataframe erhalten, welches `data` heisst. 

Im Abschnitt 2.10 - 3.5 Haben wir bei den Transaktionellen Dataframe die wichtigsten Features extrahiert, von den Kunden die eine Karte besitzt ein Roll-up Fenster inklusivem Lag Fenster bestummen und die Transkationsdaten entsprechend in dem Zeitbereich gefiltert und Funktionen zur Visualisierung der Balance geschrieben. 

Im Abschnitt 4 bis und mit 4.3.5 haben wir ein fiktives issued.date für unsere potenziellen Kunden die keine Karte besitzen bestummen, indem wir das Roll-up Fenster von Kunden pivotiert haben auf Jahr-Monat und für vorhandene Transaktion eine 1 hinzugefügt haben und eine 0 für keine Transaktion, anschliessend analog das gleiche mit den potenziellen Kunden getan und dann den Jaccard Index berechnet und daraus von den potenziellen Kunden, ein fiktives issued.date abgeleitet. Ein wichtiger Punkt dabei war das pivotieren in Jahr-Monat, sowie die gleiche Anzahl an Spalten von den Karten Besitzer und potenziellen Kunden zu haben. Ein weitere wichtiger Punkt war, dass wir die account_ids für die Kartenbesitzer wie auch potenzielle Kunden indexiert haben, da diese bei der Jaccard-Berechnungen stören und anschliessend aufgrund vom Index auf unsere account_ids der Kartenbesitzer wie auch potenzielle Kunden wieder zugewiesen haben. Damit in diesem wichtigen Schritt keine Falsche Zuweisungen stattfinden, wurde davor nach account_ids aufsteigend sortiert. Weiter gab es mehrere gleiche maximal höchste Jaccard-Werte für einen potenzielle Kunden mit mehreren Kartenbesitzer, um dieses Problem zu lösen, wurde dann random ein Kartenbesitzer als Vergleich genommen. 

Abschnitt 4.4 bis 4.5 dient als Vergleich und Data Wrangling der Transaktionellen Daten für die potenziellen Kunden sowie deren Vergleich zu den Kartenbesitzer. 

Die wichtigsten Dataframes die wir brauchen sind:
`data` => grosses gejointes Dataframe
`buyers` => Transkations Dataframe von Kartenbesitzer innerhalb des Roll-up Fenster
`non_buyers` => Transkations Dataframe von potenziellen Kunden innerhalb des Roll-up Fenster

# 6. Event Bezogene Kundeninformationen 
Erzeugen event-bezogener Kundeninformationen für 12 Monate vor 
Kreditkartenkauf (analog für Nicht-Käufer).

## 6.1 Kundeninformationen extrahieren
Wir schreiben hier Funktionen die uns erlaubt, Kundeninformationen aus den Transaktions Dataframes für Käufer und Nicht-Käufer zu extrahieren.
(Vermögen und Umsätze werden in Abschnitt 7. behandelt)

```{r}
# Add sufix to column name
add_suffix <- function(data, suffix) {
  colnames(data) <- paste(colnames(data), suffix, sep = ".")
  return(data)
}

buyers <- add_suffix(buyers, "trans")
buyers
non_buyers <- add_suffix(non_buyers, "trans")
non_buyers

```

## 6.2 Kundeninformation für 12 Monate von Käufer
```{r}

```

## 6.3 Kundeninformation für 12 Monate von Nicht-Käufer
```{r}

```

# 7. Vermögen & Umsätze
Konstruieren der Vermögen und Umsätze im Rollup-Fenster auf Basis 
der Transaktionshistorie.

## 7.1 Vermögen
```{r}

```

## 7.2 Umsätze
```{r}

```

# 8. Kunden-spezifische statistische Kennzahlen
Herleiten Kunden-spezifischer, statistischer Kennzahlen für Vermögen 
und Umsätze im Rollup-Fenster mittels Funktionen.

## 8.1 Funktion
```{r}

```

## 8.2 Statistische Kennzahlen für Vermögen
```{r}

```

## 8.3 Statistische Kennzahlen für Umsätze
```{r}

```

## 9. Kombination von Event Informationen & Kreditkarten Käufer
Kombinieren event-bezogener Informationen von KreditkartenKäufern und Nicht-Käufern.

## 9.1 Kombination
```{r}

```

# 10. Bereinigung
Bereinigen unnötiger Informationen (z.B. IDs) und Überprüfen der 
Struktur der Modellierungsdaten mittels explorativer Datenanalyse.

## 10.1 Daten Bereinigen
```{r}

```

## 10.2 Daten explorieren
```{r}

```

# 11. Partitionierung
Partitionieren der Daten in Trainings- und Testdaten.

## 11.1 Train-Test Split
```{r}

```

# 12. Baseline Modell
Erstellen eines Baseline Modelles mittels logistischer Regression und 
den Informationen “Alter”, “Geschlecht”, “Domizilregion”, 
“Vermögen” und “Umsatz” vor Kreditkartenkauf. 

## 12.1 Logistische Regression
```{r}

```

# 13. Verbesserung des Baseline Modell
Systematisches Explorieren von Verbesserungsmöglichkeiten des 
Baseline Modelles durch Erweiterung erklärender Variablen, 
Verwendung anderer Algorithmen und Optimierung.

## 13.1 Erweiterung 
```{r}

```

## 13.2 Andere Algorithmen 
```{r}

```

## 13.3 Andere Optimierungen
```{r}

```

# 14. Vergleich der Modelle
Vergleichen der Kandidatenmodelle und identifizieren des bzgl. 
Performance “besten” Modelles mit ROC, AUC und Precision.

## 14.1 Modell Vergleich
```{r}

```


# 15. Top-N Kunden 
 Quantitatives Untersuchen der Unterschiede von Top-N Kunden Listen verschiedener Modelle
 
## 15.1 Top-N Kunden Vergleich von Modellen
```{r}

```

 
# 16. Wichtigkeit und Balancierung
Untersuchen der globalen Wichtigkeit der Einflussfaktoren des 
“besten” Modelles und Reduzieren des “besten” Modelles mittels 
Balancieren von globaler Wichtigkeit und Modellperformance.

## 16.1 Wichtigkeit
```{r}

```

## 16.2 Balancierung 
```{r}

```


# 17. Beschreibung 
Beschreiben des Mehrwerts des “finalen” Modelles in der Praxis.
```{r}

```

# Lieferobjekte
Die minimalen Lieferobjekte im Notebook umfassen:

## Anzahl Kreditkarten-Käufer und Nicht-Käufer mit kompletter 12 
Monate-Rollup Information (Barplot).

## Verteilung der Kaufzeitpunkte der Kreditkarten-Käufer bzw. Vergleichszeitpunkte der Nicht-Käufer (Densityplot).

## Beschreibung der konstruierten, eigenen Variablen.

## Beschreibung von Baseline und mind. 3 Kandidaten-Modellen.

## Performance-Vergleich von Baseline und mind. 3 KandidatenModellen für 10-fache Kreuzvalidierung (Metrik: ROC Kurve und AuC). PRÄDIKTIVE MODELLE Mini-Challenge Lieferobjekte

## Performance-Vergleich von Baseline und mind. 3 KandidatenModellen für Testdaten (Metriken: Konfusionsmatrix, Accuracy,Kohen’s Kappa, Matthew’s Korrelation, Precision, Recall und F1 als Tabelle, ROC Kurve und AuC als Abbildung).

## Globale Wichtigkeit der Einflussfaktoren von Baseline und mind. 3. Kandidaten-Modellen (Variable Importance Plot).

## Quantifizierung der Unterschiede von Top-5%, Top-10% KundenListen für Baseline und mind. 3 Kandidaten-Modellen (eigene Ideen).

## Modellgüte (Lift Kurve) und Einfluss zentraler Variablen des finalen Modelles (eigene Ideen, um Non-Data Scientists zu überzeugen).
